<!doctype html>

<html>

<head>
  <meta charset="utf-8">
  <title> mp4 editor idea</title>
  <script src="mp4box.all.js"></script> <!-- from https://gpac.github.io/mp4box.js/dist/mp4box.all.js -->
  
  <style>
    body {
      font-family: Arial;
    }
    
    canvas {
      border: 1px solid #000;
    }
    
    canvas:hover {
      opacity: 0.5;
    }
    
    #frames {
      display: flex;
      flex-direction: row;
      gap: 10px;
      overflow: scroll;
      margin: 2px;
    }
    
    #video {
      display: none;
    }
    
    #instructions {
      font-weight: bold;
    }
  </style>
</head>

<body>
  <h1> mp4 editor idea </h1>
  <p> currently only extracts frames from an mp4 file and allows some editing of the frames (e.g. image filters). more to come hopefully :) </p>
  <p id='instructions'> instructions: click on a frame after loading an mp4 file to edit it. click on 'save changes' to export a new mp4 file with your edits. </p>
  
  <input type="file" accept="video/mp4" onchange="start(this.files[0])">
  
  <br />
  
  <div id='frames'></div>
  
  <video controls id='video' width='350' height='350'></video>
  
  <br />
  
  <button id='saveChanges'> save changes </button>

  <script>
  let images = [];
  let frameInfo = {};
  let frameCount = 0;
  let startDate;
  let offset = 0;
  let fileSize = 0;
  let currMp4Info = null;
  let currFile = null;
  let canvasContextMenu = null;
  const chunkSize  = 1024 * 1024; // bytes

  let mp4Box = null;
  let decoder = null;

  const onparsedbuffer = (mp4box, buffer) => {
    //console.log(`Appending buffer with offset: ${offset}`);
    buffer.fileStart = offset;
    mp4box.appendBuffer(buffer);
  }

  const readBlock = (_offset, length, _file) => {
    const reader = new FileReader();
    const blob = _file.slice(_offset, length + _offset);
    reader.onload = onBlockRead;
    reader.readAsArrayBuffer(blob);
  }

  const onBlockRead = (evt) => {
    if(evt.target.error == null){
      onparsedbuffer(mp4Box, evt.target.result); // callback for handling read chunk
      offset += evt.target.result.byteLength;
    }else{
      console.log(`Read error: ${evt.target.error}`);
      return;
    }
    
    if(offset >= fileSize){
      console.log(`Done reading file (${fileSize} bytes) in ${new Date() - startDate} ms`);
      mp4Box.flush();
      return;
    }

    readBlock(offset, chunkSize, currFile);
  }

  function clearFrameCanvases(){
    const parent = document.getElementById('frames');
    while(parent.lastChild){
      parent.removeChild(parent.lastChild);
    }
  }

  function getDescription(track, mp4box){
    const tr = mp4box.getTrackById(track.id);
    for(const entry of tr.mdia.minf.stbl.stsd.entries){
      if(entry.avcC || entry.hvcC){
        const stream = new DataStream(undefined, 0, DataStream.BIG_ENDIAN);
        if(entry.avcC){
          entry.avcC.write(stream);
        }else{
          entry.hvcC.write(stream);
        }
        return new Uint8Array(stream.buffer, 8);
      }
    }
    throw "avcC or hvcC not found";
  }

  function invertImage(imgData){
    const d = imgData.data;
    let r, g, b, x, y, z;
    for(let i = 0; i < d.length; i += 4){
      r = d[i];
      g = d[i + 1];
      b = d[i + 2];
      d[i] = 255 - r;
      d[i + 1] = 255 - g;
      d[i + 2] = 255 - b;
    }
  }
  
  function edgeDetection(imgData){
    const width = imgData.width;
    const height = imgData.height;
    const data = imgData.data;

    const sourceImageCopy = new Uint8ClampedArray(data);

    const xKernel = [[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]];
    const yKernel = [[-1, -2, -1], [0, 0, 0], [1, 2, 1]];

    for(let i = 1; i < height - 1; i++){
      for(let j = 4; j < 4 * width - 4; j += 4){
        const left = (4 * i * width) + (j - 4);
        const right = (4 * i * width) + (j + 4);
        const top = (4 * (i - 1) * width) + j;
        const bottom = (4 * (i + 1) * width) + j;
        const topLeft = (4 * (i - 1) * width) + (j - 4);
        const topRight = (4 * (i - 1) * width) + (j + 4);
        const bottomLeft = (4 * (i + 1) * width) + (j - 4);
        const bottomRight = (4 * (i + 1) * width) + (j + 4);
        const center = (4 * width * i) + j;

        // use the xKernel to detect edges horizontally 
        const pX = (xKernel[0][0] * sourceImageCopy[topLeft]) + (xKernel[0][1] * sourceImageCopy[top]) + (xKernel[0][2] * sourceImageCopy[topRight]) +
                   (xKernel[1][0] * sourceImageCopy[left]) + (xKernel[1][1] * sourceImageCopy[center]) + (xKernel[1][2] * sourceImageCopy[right]) +
                   (xKernel[2][0] * sourceImageCopy[bottomLeft]) + (xKernel[2][1] * sourceImageCopy[bottom]) + (xKernel[2][2] * sourceImageCopy[bottomRight]);

        // use the yKernel to detect edges vertically 
        const pY = (yKernel[0][0] * sourceImageCopy[topLeft]) + (yKernel[0][1] * sourceImageCopy[top]) + (yKernel[0][2] * sourceImageCopy[topRight]) +
                   (yKernel[1][0] * sourceImageCopy[left]) + (yKernel[1][1] * sourceImageCopy[center]) + (yKernel[1][2] * sourceImageCopy[right]) +
                   (yKernel[2][0] * sourceImageCopy[bottomLeft]) + (yKernel[2][1] * sourceImageCopy[bottom]) + (yKernel[2][2] * sourceImageCopy[bottomRight]);

        // finally set the current pixel to the new value based on the formula 
        const newVal = (Math.ceil(Math.sqrt((pX * pX) + (pY * pY))));
        data[center] = newVal;
        data[center + 1] = newVal;
        data[center + 2] = newVal;
        data[center + 3] = 255;
      }
    }
  }

  function createMp4Box(){
    const mp4Box = MP4Box.createFile(false);

    mp4Box.onError = (e) => {
      console.log("Failed to parse ISOBMFF data");
    };

    mp4Box.onSidx = (sidx) => {
      console.log(sidx);
    };

    mp4Box.onReady = function(info){
      console.log(info);
      currMp4Info = info;
      
      // do stuff with mp4 data
      const track = info.videoTracks[0];
      
      const videoDecoderConfig = {
        codec: '',
        codedHeight: 0,
        codedWidth: 0,
        description: null,
        info: null,
      };
      
      videoDecoderConfig.codec = track.codec;
      videoDecoderConfig.codedHeight = track.video.height;
      videoDecoderConfig.codedWidth = track.video.width;
      videoDecoderConfig.info = info;
      videoDecoderConfig.description = getDescription(track, this);
      
      // https://github.com/josephrocca/getVideoFrames.js/blob/main/mod.js
      decoder = new VideoDecoder({
        output: (frame) => {  // `frame` is a VideoFrame object: https://developer.mozilla.org/en-US/docs/Web/API/VideoFrame
          //console.log(`adding canvas: ${frameCount}`);
          const canvas = document.createElement('canvas');
          canvas.id = `frame_${frameCount}`;
          canvas.width = track.video.width;
          canvas.height = track.video.height;
          
          // TODO: do something more interesting here
          
          /*
          canvas.addEventListener('click', (evt) => {
            const canvasCtx = canvas.getContext('2d');
            const imgData = canvasCtx.getImageData(0, 0, canvas.width, canvas.height);
            edgeDetection(imgData);
            canvasCtx.putImageData(imgData, 0, 0);
          });
          */
          
          canvas.addEventListener('pointerdown', (evt) => {
            if(canvasContextMenu){
              canvasContextMenu.parentNode.removeChild(canvasContextMenu);
              canvasContextMenu = null;
            }
            
            createCanvasContextMenu(canvas);
          });
          
          const ctx = canvas.getContext('2d');
          ctx.drawImage(frame, 0, 0, canvas.width, canvas.height);
          
          frame.close();
          
          //images.push(canvas);
          
          document.getElementById('frames').appendChild(canvas);
          
          frameCount++;
        },
        error: (e) => {
          console.error(e);
        },
      });
      
      decoder.configure(videoDecoderConfig);
      
      this.setExtractionOptions(track.id);
      this.start();
    }

    mp4Box.onSamples = async (track_id, ref, samples) => {
      console.log(`got samples - num samples: ${samples.length}`);
      
      let sampleCount = 0;
      for(const sample of samples){
        // this is async
        frameInfo[sampleCount] = {
          timestamp: 1e6 * sample.cts / sample.timescale,
          duration: sample.duration,
          cts: sample.cts,
          dts: sample.dts,
          sample_num: sampleCount,
        };
        
        //console.log(`processing sample ${sampleCount++}`);
        
        decoder.decode(new EncodedVideoChunk({
          type: sample.is_sync ? "key" : "delta",
          timestamp: 1e6 * sample.cts / sample.timescale,
          duration: 1e6 * sample.duration / sample.timescale,
          data: sample.data
        }));
        
        sampleCount++;
      }
      
      // flush the decoder since we're done reading the samples. this is important to get all the frames.
      // see https://stackoverflow.com/questions/74098842/videodecoder-decode-output-not-called
      await decoder.flush();
    }
    
    return mp4Box;
  }

  // https://gpac.github.io/mp4box.js/test/ui-helper.js
  function parseFile(fileobj){
    fileSize = fileobj.size;
    startDate = new Date();
    offset = 0;
    frameCount = 0;
    
    clearFrameCanvases();
    images = [];
    frameInfo = {};
    
    mp4Box = createMp4Box();
    
    readBlock(offset, chunkSize, fileobj);
  }

  function start(fileobj){
    currFile = fileobj;
    parseFile(fileobj);
    
    // https://stackoverflow.com/questions/5235145/changing-source-on-html5-video-tag
    const video = document.getElementById('video');
    video.style.display = 'block';
    
    const source = document.createElement('source');
    source.setAttribute('src', URL.createObjectURL(fileobj));
    source.setAttribute('type', 'video/mp4');
    
    // clear any children of video element
    while(video.lastChild){
      video.removeChild(video.lastChild);
    }
    
    video.appendChild(source);
    video.load();
  }

  // TODO: viewing an exported mp4 doesn't look too good on Windows but in Discord for example it 
  // seems to render fine? why is that?
  async function saveChanges(){
    console.log(frameInfo);
    const canvasFrames = document.querySelectorAll('canvas');
    if(canvasFrames.length > 0 && currMp4Info.videoTracks.length === 1){
      // TODO: fyi we're only asuming one video track here.
      const codec = currMp4Info.videoTracks[0].codec;
      //console.log(codec);
      
      const frameWidth = canvasFrames[0].width;
      const frameHeight = canvasFrames[0].height;
      const totalFrames = canvasFrames.length;
      const fps = 120; // TODO: how do I get the right fps?
      
      // NOTE: we are assuming right now that the number of frames hasn't changed
      // and so the duration should be the same as the original mp4
      const durationPerFrame = currMp4Info.nb_samples / currMp4Info.duration;
      
      const trackOptions = {
        timescale: currMp4Info.videoTracks[0].timescale,
        width: frameWidth,
        height: frameHeight,
        nb_samples: totalFrames,
        codec: codec,
        duration: currMp4Info.videoTracks[0].duration - (currMp4Info.nb_samples * durationPerFrame),
      };
      
      const file = MP4Box.createFile();
      
      // copy over some info from the loaded mp4 we're editing
      // TODO: does this really matter?
      // https://github.com/gpac/mp4box.js/blob/master/src/isofile-advanced-creation.js#L4
      file.init({
        brands: currMp4Info.brands,
        timescale: currMp4Info.timescale,
        duration: currMp4Info.duration,
      });
      
      let trackId = null;
      let chunkCount = 0;
      const videoEncoder = new VideoEncoder({
        output: (chunk, config) => {
          const buffer = new ArrayBuffer(chunk.byteLength);
          chunk.copyTo(buffer);
          
          if(trackId == null){
            trackOptions.avcDecoderConfigRecord = config.decoderConfig.description;
            trackId = file.addTrack(trackOptions);
          }
          
          //console.log(`chunk timestamp: ${chunk.timestamp}`);        
          const sampleData = frameInfo[chunkCount];
          //console.log(sampleData);
          
          const sampleOptions = {
            duration: sampleData.duration,
            dts: sampleData.dts,
            cts: sampleData.cts,
            is_sync: chunk.type === 'key',
          };
          
          chunkCount++;
          
          // add new frame as sample to the mp4 file
          file.addSample(trackId, buffer, sampleOptions);
        },
        error: err => console.error('VideoEncoder error: ', err)
      });
      
      await videoEncoder.configure({
        codec: codec,
        width: frameWidth,
        height: frameHeight,
        bitrate: currMp4Info.videoTracks[0].bitrate,
        framerate: fps,
      });
      
      // add the frames to the video encoder
      for(let index = 0; index < totalFrames; index++){
        const bitmap = await createImageBitmap(canvasFrames[index]);
        const videoFrame = new VideoFrame(bitmap, {
          timestamp: frameInfo[index].timestamp,
        });
        videoEncoder.encode(videoFrame);
        videoFrame.close();
        bitmap.close();
      };
      
      await videoEncoder.flush();
      
      // TODO: add audio if present as well
      
      file.save('editedVideo.mp4'); // TODO: allow user to name edited file
    }
  }

  document.getElementById('saveChanges').addEventListener('click', () => saveChanges());
  
  function createCanvasContextMenu(canvasTargetElement){
    const menu = document.createElement('div');
    menu.style.position = 'absolute';
    menu.style.top = (canvasTargetElement.getBoundingClientRect().top + window.scrollY) + 'px';
    menu.style.left = (canvasTargetElement.getBoundingClientRect().left + window.scrollX) + 'px';
    menu.style.border = '1px solid #000';
    menu.style.backgroundColor = 'rgba(255, 255, 255, 125)';
    menu.style.width = canvasTargetElement.style.width + 'px';
    menu.style.height = canvasTargetElement.style.height + 'px';
    menu.style.display = 'block';
    
    //const p = document.createElement('p');
    //p.textContent = 'asdfnjknsdklf';
    //menu.appendChild(p);
    
    const select = document.createElement('select');
    const options = ['', 'invert filter', 'edge detection filter', 'delete'];
    options.forEach(opt => {
      const o = document.createElement('option');
      o.textContent = opt;
      select.appendChild(o);
    });
    
    select.addEventListener('change', evt => {
      const canvasCtx = canvasTargetElement.getContext('2d');
      const imgData = canvasCtx.getImageData(0, 0, canvasTargetElement.width, canvasTargetElement.height);
      
      const selected = evt.target.value;
      
      if(selected === 'invert filter'){
        invertImage(imgData);
        canvasCtx.putImageData(imgData, 0, 0);        
      }else if(selected === 'edge detection filter'){
        edgeDetection(imgData);
        canvasCtx.putImageData(imgData, 0, 0);
      }else if(selected === 'delete'){
        canvasTargetElement.parentNode.removeChild(canvasTargetElement);
        if(canvasContextMenu){
          canvasContextMenu.parentNode.removeChild(canvasContextMenu);
          canvasContextMenu = null;
        }
      }
    });
    
    menu.appendChild(select);
    
    document.body.appendChild(menu);
    
    canvasContextMenu = menu;
  }

  document.body.addEventListener('pointerdown', evt => {
    if(evt.target.tagName !== 'CANVAS' && evt.target.tagName !== 'SELECT' && canvasContextMenu){
      canvasContextMenu.parentNode.removeChild(canvasContextMenu);
      canvasContextMenu = null;
    }
  });

  </script>
</body>

</html>