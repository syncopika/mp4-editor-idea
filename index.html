<!doctype html>

<html>

<head>
  <meta charset="utf-8">
  <title> mp4 editor idea</title>
  <script src="mp4box.all.js"></script> <!-- from https://gpac.github.io/mp4box.js/dist/mp4box.all.js -->
  
  <style>
    body {
      font-family: Arial;
    }
    
    canvas {
      border: 1px solid #000;
    }
    
    #frames {
      display: flex;
      flex-direction: row;
      gap: 10px;
      overflow: scroll;
      margin: 2px;
    }
  </style>
</head>

<body>
  <h1>mp4 editor idea</h1>
  <p> not an actual editor yet but it can extract frames from an mp4 file :D and more to come hopefully </p>
  <!--<button id='importFile'>import file</button>-->
  <input type="file" accept="video/mp4" onchange="start(this.files[0])">
  
  <br />
  
  <div id='frames'></div>
  
  <br />
  
  <button id='saveChanges'> save changes </button>

<script>
//https://gpac.github.io/mp4box.js/#demos
//https://gpac.github.io/mp4box.js/#extraction
//https://developer.mozilla.org/en-US/docs/Web/API/WebCodecs_API
//https://stackoverflow.com/questions/32699721/javascript-extract-video-frames-reliably

let images = [];
let frameInfo = {};
let frameCount = 0;
let startDate;
let offset = 0;
let fileSize = 0;
let currMp4Info = null;
let currFile = null;
const chunkSize  = 1024 * 1024; // bytes

let mp4Box = null;
let videoDecoder = null;

const onparsedbuffer = (mp4box, buffer) => {
  console.log(`Appending buffer with offset: ${offset}`);
  buffer.fileStart = offset;
  mp4box.appendBuffer(buffer);
}

const readBlock = (_offset, length, _file) => {
  const reader = new FileReader();
  const blob = _file.slice(_offset, length + _offset);
  reader.onload = onBlockRead;
  reader.readAsArrayBuffer(blob);
}

const onBlockRead = (evt) => {
  if(evt.target.error == null){
    onparsedbuffer(mp4Box, evt.target.result); // callback for handling read chunk
    offset += evt.target.result.byteLength;
    //progressbar.progressbar({ value: Math.ceil(100*offset/fileSize) });
  }else{
    console.log(`Read error: ${evt.target.error}`);
    //finalizeUI(fileobj, loadbutton, false);
    return;
  }
  
  if(offset >= fileSize){
    //progressbar.progressbar({ value: 100 });
    console.log(`Done reading file (${fileSize} bytes) in ${new Date() - startDate} ms`);
    mp4Box.flush();
    //finalizeUI(fileobj, loadbutton, true);
    return;
  }

  readBlock(offset, chunkSize, currFile);
}

function clearFrameCanvases(){
  const parent = document.getElementById('frames');
  while(parent.lastChild){
    parent.removeChild(parent.lastChild);
  }
}

function getDescription(track, mp4box){
  const tr = mp4box.getTrackById(track.id);
  for(const entry of tr.mdia.minf.stbl.stsd.entries){
    if(entry.avcC || entry.hvcC){
      const stream = new DataStream(undefined, 0, DataStream.BIG_ENDIAN);
      if(entry.avcC){
        entry.avcC.write(stream);
      }else{
        entry.hvcC.write(stream);
      }
      return new Uint8Array(stream.buffer, 8);
    }
  }
  throw "avcC or hvcC not found";
}

function invertImage(imgData){
  const d = imgData.data;
  let r, g, b, x, y, z;
  for(let i = 0; i < d.length; i += 4){
    r = d[i];
    g = d[i + 1];
    b = d[i + 2];
    d[i] = 255 - r;
    d[i + 1] = 255 - g;
    d[i + 2] = 255 - b;
  }
}

function createMp4Box(){
  const mp4Box = MP4Box.createFile(false);

  mp4Box.onError = (e) => {
    console.log("Failed to parse ISOBMFF data");
  };

  mp4Box.onSidx = (sidx) => {
    console.log(sidx);
  };

  mp4Box.onReady = function(info){
    console.log(info);
    currMp4Info = info;
    
    // do stuff with mp4 data
    const track = info.videoTracks[0];
    
    const videoDecoderConfig = {
      codec: '',
      codedHeight: 0,
      codedWidth: 0,
      description: null,
      info: null,
    };
    
    videoDecoderConfig.codec = track.codec;
    videoDecoderConfig.codedHeight = track.video.height;
    videoDecoderConfig.codedWidth = track.video.width;
    videoDecoderConfig.info = info;
    videoDecoderConfig.description = getDescription(track, this);
    
    // https://github.com/josephrocca/getVideoFrames.js/blob/main/mod.js
    decoder = new VideoDecoder({
      output: (frame) => {  // `frame` is a VideoFrame object: https://developer.mozilla.org/en-US/docs/Web/API/VideoFrame
        //console.log(`writing frame: ${frameCount}`);
        
        /*
        frameInfo[frameCount] = {
          timestamp: frame.timestamp,
          duration: frame.duration,
        };*/
        
        console.log(`adding canvas: ${frameCount}`);
        
        const canvas = document.createElement('canvas');
        canvas.id = `frame_${frameCount}`;
        canvas.width = track.video.width;
        canvas.height = track.video.height;
        
        // TODO: do something more interesting here
        canvas.addEventListener('click', (evt) => {
          const canvasCtx = canvas.getContext('2d');
          const imgData = canvasCtx.getImageData(0, 0, canvas.width, canvas.height);
          invertImage(imgData);
          canvasCtx.putImageData(imgData, 0, 0);
        });
        
        const ctx = canvas.getContext('2d');
        ctx.drawImage(frame, 0, 0, canvas.width, canvas.height);
        
        frame.close();
        
        //images.push(canvas);
        
        document.getElementById('frames').appendChild(canvas);
        
        frameCount++;
      },
      error: (e) => {
        console.error(e);
        //setStatus("decode", e);
      },
    });
    
    decoder.configure(videoDecoderConfig);
    
    this.setExtractionOptions(track.id);
    this.start();
  }

  mp4Box.onSamples = (track_id, ref, samples) => {
    console.log(`got samples - num samples: ${samples.length}`);
    
    let sampleCount = 0;
    for(const sample of samples){
      // this is async
      frameInfo[sampleCount] = {
        timestamp: 1e6 * sample.cts / sample.timescale,
        duration: sample.duration,
        cts: sample.cts,
        dts: sample.dts,
        sample_num: sampleCount,
      };
      
      console.log(`processing sample ${sampleCount++}`);
      
      decoder.decode(new EncodedVideoChunk({
        type: sample.is_sync ? "key" : "delta",
        timestamp: 1e6 * sample.cts / sample.timescale,
        duration: 1e6 * sample.duration / sample.timescale,
        data: sample.data
      }));
    }
  }
  
  return mp4Box;
}

// https://gpac.github.io/mp4box.js/test/ui-helper.js
function parseFile(fileobj){
  fileSize = fileobj.size;
  startDate = new Date();
  offset = 0;
  frameCount = 0;
  
  clearFrameCanvases();
  images = [];
  frameInfo = {};
  
  mp4Box = createMp4Box();
  
  readBlock(offset, chunkSize, fileobj);
}

function start(fileobj){
  currFile = fileobj;
  parseFile(fileobj);
}

// helpful? https://github.com/gpac/mp4box.js/issues/243
// also https://github.com/gpac/mp4box.js/issues/243#issuecomment-1884708434
// https://stackoverflow.com/questions/73386981/get-a-frame-count-of-a-mp4-file
async function saveChanges(){
  console.log(frameInfo);
  const canvasFrames = document.querySelectorAll('canvas');
  if(canvasFrames.length > 0 && currMp4Info.videoTracks.length === 1){
    // TODO: fyi we're only asuming one video track here.
    
    const codec = currMp4Info.videoTracks[0].codec; //'avc1.640016';
    const frameWidth = canvasFrames[0].width;
    const frameHeight = canvasFrames[0].height;
    const totalFrames = canvasFrames.length; //currMp4Info.videoTracks[0].nb_samples; // it doesn't appear that there's necessarily a 1:1 relationship between samples and frames
    const fps = 120; // TODO: how do I get the right fps?
    
    // NOTE: we are assuming right now that the number of frames hasn't changed
    // and so the duration should be the same as the original mp4
    
    const trackOptions = {
      timescale: currMp4Info.videoTracks[0].timescale,
      width: frameWidth,
      height: frameHeight,
      nb_samples: totalFrames,
      codec: codec,
    };
    
    const file = MP4Box.createFile();
    
    let trackId = null;
    let chunkCount = 0;
    const videoEncoder = new VideoEncoder({
      output: (chunk, config) => {
        const buffer = new ArrayBuffer(chunk.byteLength);
        chunk.copyTo(buffer);
        
        if(trackId == null){
          trackOptions.avcDecoderConfigRecord = config.decoderConfig.description;
          trackId = file.addTrack(trackOptions);
        }
        
        //console.log(`chunk timestamp: ${chunk.timestamp}`);        
        const sampleData = frameInfo[chunkCount];
        //console.log(chunkCount);
        console.log(sampleData);
        
        const sampleOptions = {duration: chunk.duration}; //chunk.duration / 1000};
        sampleOptions.dts = sampleData.dts, //chunk.timestamp / 1000; // 1000 for 1 ms
        sampleOptions.cts = sampleData.cts, //chunk.timestamp / 1000;
        sampleOptions.is_sync = chunk.type === 'key';
        
        chunkCount++;
        
        file.addSample(trackId, buffer, sampleOptions);
      },
      error: err => console.error('VideoEncoder error: ', err)
    });
    
    await videoEncoder.configure({
      codec: codec,
      width: frameWidth,
      height: frameHeight,
      bitrate: currMp4Info.videoTracks[0].bitrate,
      framerate: fps,
    });
    
    // add the frames to the video encoder
    for(let index = 0; index < totalFrames; index++){
      const bitmap = await createImageBitmap(canvasFrames[index]);
      const videoFrame = new VideoFrame(bitmap, {
        timestamp: frameInfo[index].timestamp,
      });
      videoEncoder.encode(videoFrame);
      videoFrame.close();
      bitmap.close();
    };
    
    await videoEncoder.flush();
    
    // TODO: add audio if present as well
    
    file.save('editedVideo.mp4'); // TODO: allow user to name edited file
  }
}

document.getElementById('saveChanges').addEventListener('click', () => saveChanges());

</script>

</body>

</html>