<!doctype html>

<html>

<head>
  <meta charset="utf-8">
  <title> mp4 editor idea </title>
  <script src="mp4box.all.js"></script> <!-- from https://gpac.github.io/mp4box.js/dist/mp4box.all.js -->
  <script src="./utils.js"></script>
  <script src="./modal.js"></script>
  <style>
    body {
      font-family: Arial;
    }
    
    canvas {
      border: 1px solid #000;
    }
    
    h1 {
      text-align: center;
    }
    
    .canvas:hover {
      opacity: 0.5;
    }
    
    .modal {
      display: none;
    }
    
    #selectFile {
      margin-bottom: 1.3em;
    }
    
    #options {
      display: flex;
      gap: 10px;
    }
    
    #frames {
      display: flex;
      flex-direction: row;
      gap: 10px;
      overflow: scroll;
      margin: 2px;
    }
    
    #resizeFrames {
      vertical-align: middle;
      margin: 0;
    }
    
    #seekStart, #seekEnd {
      width: 60px;
    }
    
    #video {
      display: none;
    }
    
    #instructions {
      font-weight: bold;
    }
    
    #status {
      color: #228b22;
    }
    
    #notes {
      color: #00a;
      font-weight: bold;
    }
    
    #notes:hover {
      cursor: pointer;
    }
    
    #resizeFramesLabel {
      vertical-align: middle;
    }
  </style>
</head>

<body>
  <h1> mp4 editor idea </h1>
  <p> extracts frames from an mp4 file using mp4box.js and allows some editing of the frames (e.g. image filters, drawing). more to come hopefully :) - <span id='notes'>see notes on current limitations </span></p>
  
  <!--
  <p> Notes: </p>
  <p> This has not been tested yet on mp4 files longer than 10 minutes. </p>
  <p> Only up to 100 frames will be displayed at a time. Seeking is limited to a range of 5 seconds currently. </p>
  <p> Additionally, when saving edits, the image quality unfortunately is not preserved (so it may look worse than the source file) and any audio tracks are not included in the output. </p>
  -->
  
  <p id='instructions'> instructions: click on a frame after loading an mp4 file to edit it. click on 'save changes' to export a new mp4 file with your edits. When drawing mode is active, click on the gray background to end drawing. </p>
  
  <input id='selectFile' type='file' accept='video/mp4' onchange='start(this.files[0])'>
  
  <button id='reloadFile'> reload file </button>
  
  <!-- options -->
  <div id='options'>
    <div>
      <label id='resizeFramesLabel' for='resizeFrames'> resize frames on load: </label>
      <input type='checkbox' id='resizeFrames' checked />
    </div>
    
    <div>
      <label for='seekStart'> seek start (sec): </label>
      <input type='number' id='seekStart' />
    </div>
      
    <div>
      <label for='seekEnd'> seek end (sec): </label>
      <input type='number' id='seekEnd' />
    </div>
    
    <button id='seek'> seek </button>
  </div>
  
  <hr />
  
  <!-- info -->
  
  <p> num samples/frames: <span id='numSamples'></span></p>
  
  <p> estimated frames-per-second: <span id='estimatedFps'></span></p>
  
  <p id='status'></p>
  
  <div id='frames'></div>
  
  <video controls id='video' width='350' height='350'></video>
  
  <hr />
  
  <label for='filenameToSave'> name of file to export: </label>
  <input id='filenameToSave' type='text' />

  <button id='saveChanges'> save changes </button>
  
  <modal-component id='notesModal' class='modal'>
    <p>Notes:</p>
    <p>This has not been tested yet on mp4 files longer than 10 minutes so success with such files may vary (that said, there may be small mp4 files that may break this app as well :D ).</p>
    <p>Only up to 100 frames will be displayed at a time. Seeking is currently limited to a range of 5 seconds.</p>
    <p>Additionally, when saving edits, the image quality unfortunately is not preserved (so it may look worse than the source file) and any audio tracks are not included in the output.</p>
  </modal-component>
  
  <modal-component id='seekLimitModal' class='modal'>
    <p> Seek limit is currently set to 5 seconds, sorry! </p>
  </modal-component>
  
  <modal-component id='seekValuesInvalidModal' class='modal'>
    <p> seekStart or seekEnd is less than 0, which is invalid. </p>
  </modal-component>
  
  <modal-component id='seekStartTooLargeModal' class='modal'>
    <p> seekStart is larger than or equal to the duration of the mp4 file. seekStart should be at least 0 but less than the duration of the file. </p>
  </modal-component>
  
  <modal-component id='seekEndTooSmallModal' class='modal'>
    <p> seekEnd is less than or equal to seekStart. seekEnd should be larger than seekStart. </p>
  </modal-component>
  
  <modal-component id='seekEndTooLargeModal' class='modal'>
    <p> seekEnd is larger than the duration of the mp4 file. </p>
  </modal-component>
  
  <modal-component id='stillProcessing' class='modal'>
    <p> File is still being processed... </p>
  </modal-component>

  <script>
  let images = [];
  let frameInfo = {};
  let frameCount = 0;
  let startDate;
  let offset = 0;
  let fileSize = 0;
  let sampleCount = 0;
  let samplesProcessed = 0;
  let seekStart = 0;
  let seekEnd = 0;
  let isProcessing = false;
  let isSeeking = false;
  let currMp4Info = null;
  let currFile = null;
  let canvasContextMenu = null;
  const frameLimit = 100; // how many frames allowed to be displayed at a time
  const chunkSize  = 1024 * 1024; // bytes

  let mp4Box = null;
  let decoder = null;
  
  const canvasUtils = new CanvasUtils();

  const onparsedbuffer = (mp4box, buffer) => {
    //console.log(`Appending buffer with offset: ${offset}`);
    buffer.fileStart = offset;
    mp4box.appendBuffer(buffer);
  };

  const readBlock = (_offset, length, _file) => {
    const reader = new FileReader();
    const blob = _file.slice(_offset, length + _offset);
    reader.onload = onBlockRead;
    reader.readAsArrayBuffer(blob);
  };

  const onBlockRead = async (evt) => {
    if(evt.target.error == null){
      onparsedbuffer(mp4Box, evt.target.result); // callback for handling read chunk
      offset += evt.target.result.byteLength;
    }else{
      console.log(`Read error: ${evt.target.error}`);
      return;
    }
    
    if(offset >= fileSize){
      console.log(`Done reading file (${fileSize} bytes) in ${new Date() - startDate} ms`);
      
      // flush the decoder since we're done reading the samples. this is important to get all the frames.
      // see https://stackoverflow.com/questions/74098842/videodecoder-decode-output-not-called
      await decoder.flush();
      mp4Box.flush();
      
      isProcessing = false;
      
      return;
    }

    readBlock(offset, chunkSize, currFile);
  };

  function clearFrameCanvases(){
    const parent = document.getElementById('frames');
    while(parent.lastChild){
      parent.removeChild(parent.lastChild);
    }
  }

  function getDescription(track, mp4box){
    const tr = mp4box.getTrackById(track.id);
    for(const entry of tr.mdia.minf.stbl.stsd.entries){
      if(entry.avcC || entry.hvcC){
        const stream = new DataStream(undefined, 0, DataStream.BIG_ENDIAN);
        if(entry.avcC){
          entry.avcC.write(stream);
        }else{
          entry.hvcC.write(stream);
        }
        return new Uint8Array(stream.buffer, 8);
      }
    }
    throw "avcC or hvcC not found";
  }
  
  function clampDimensions(width, height, maxWidth, maxHeight){
    if(width > maxWidth || height > maxHeight){
      const ratio = height / width;
      while(width > maxWidth || height > maxHeight){
        width -= 1;
        height -= ratio;
      }
      
      // frames need to have even-sized dimensions when using the H264 codec
      // TODO: do we have to use H264? need to research some more
      if(width % 2 != 0){
        width--;
      }
      
      height = Math.round(height);
      if(height % 2 != 0){
        height--;
      }
    }
    
    return {width, height};
  }

  function createMp4Box(){
    const mp4Box = MP4Box.createFile(false);

    mp4Box.onError = (e) => {
      console.log("Failed to parse ISOBMFF data");
    };

    mp4Box.onSidx = (sidx) => {
      console.log(sidx);
    };

    mp4Box.onReady = function(info){
      console.log(info);
      currMp4Info = info;
      
      const track = info.videoTracks[0];
      
      // estimate frames-per-second (fps)
      const duration = track.duration;
      const timescale = track.timescale;
      const numSamples = track.nb_samples;
      document.getElementById('numSamples').textContent = numSamples;
      
      let fps = Math.round(numSamples / (duration / timescale));
      
      if(fps === Infinity){
        // duration may be 0
        //console.log(`duration: ${duration}, timescale: ${timescale}`);
        console.log('fps is Infinity. will try to use info.duration and info.timescale instead.');
        fps = Math.round(numSamples / (info.duration / info.timescale));
      }
      
      document.getElementById('estimatedFps').textContent = fps;
      
      const videoDecoderConfig = {
        codec: '',
        codedHeight: 0,
        codedWidth: 0,
        description: null,
        info: null,
      };
      
      videoDecoderConfig.codec = track.codec;
      videoDecoderConfig.codedHeight = track.video.height;
      videoDecoderConfig.codedWidth = track.video.width;
      videoDecoderConfig.info = info;
      videoDecoderConfig.description = getDescription(track, this);
      
      if(isSeeking){
        document.getElementById('status').textContent = 'seeking in progress...';
      }else{
        document.getElementById('status').textContent = 'processing samples...';
      }
      
      // https://github.com/josephrocca/getVideoFrames.js/blob/main/mod.js
      decoder = new VideoDecoder({
        output: (frame) => {  // `frame` is a VideoFrame object: https://developer.mozilla.org/en-US/docs/Web/API/VideoFrame
          //console.log(`adding canvas: ${frameCount}`);
          samplesProcessed++;
          
          const currTimeInSec = frame.timestamp / 1e6;
          
          /*
          if(isSeeking){
            console.log(`curr time: ${currTimeInSec}, seekStart: ${seekStart}, seekEnd: ${seekEnd}, isSeeking: ${isSeeking}, total duration: ${track.duration / track.timescale}, sample num: ${samplesProcessed}`);
          }*/
          
          // if we're seeking for a range, ignore all samples not in range
          if(isSeeking && currTimeInSec < seekStart){
            frame.close();
            return;
          }else if(isSeeking && samplesProcessed < track.nb_samples && currTimeInSec > seekEnd){
            // done seeking
            frame.close();
            return;
          }else if(isSeeking && samplesProcessed === track.nb_samples){
            // reset isSeeking after we've processed all samples
            document.getElementById('status').textContent = '';
            isSeeking = false;
            console.log('all samples processed after seek');
            
            if(currTimeInSec > seekEnd){
              frame.close();
              return;
            }
          }else if(!isSeeking && samplesProcessed === track.nb_samples){
            document.getElementById('status').textContent = '';
            console.log('all samples processed.');
          }
          
          // try to prevent potentially bad things from happening
          // if it's a big mp4 and there are lots of frames by limiting canvas creation
          // TODO: is there a better way to warn a user about large mp4 files?
          if(frameCount > frameLimit){
            //console.log('frameCount is over 100! no more canvas elements for frames will be created.');
            frame.close();
            isSeeking = false;
            return;
          }
          
          const canvas = document.createElement('canvas');
          canvas.classList.add('canvas');
          canvas.id = `frame_${frameCount}`;
          
          const shouldResizeFrames = document.getElementById('resizeFrames').checked;
          if(shouldResizeFrames){
            const {width, height} = clampDimensions(track.video.width, track.video.height, 400, 400);
            canvas.width = width;
            canvas.height = height;
          }else{
            canvas.width = track.video.width;
            canvas.height = track.video.height;
          }
          
          canvas.addEventListener('pointerdown', (evt) => {
            if(canvasContextMenu){
              canvasContextMenu.parentNode.removeChild(canvasContextMenu);
              canvasContextMenu = null;
            }     
            createCanvasContextMenu(canvas);
          });
          
          const ctx = canvas.getContext('2d');
          ctx.drawImage(frame, 0, 0, canvas.width, canvas.height);
          
          frame.close();
          
          //images.push(canvas);
          
          document.getElementById('frames').appendChild(canvas);
          
          frameCount++;
        },
        error: (e) => {
          console.error(e);
        },
      });
      
      decoder.configure(videoDecoderConfig);
      
      this.setExtractionOptions(track.id);
      
      isProcessing = true;
      
      this.start();
    };

    mp4Box.onSamples = (track_id, ref, samples) => {
      console.log(`got samples - num samples: ${samples.length}`);
      
      for(const sample of samples){
        //console.log(`curr time in sec: ${currTimeInSec}`);
        //currTimeInSec += (sample.duration / sample.timescale);
        
        frameInfo[sampleCount] = {
          timestamp: 1e6 * sample.cts / sample.timescale,
          duration: sample.duration,
          cts: sample.cts,
          dts: sample.dts,
          sample_num: sampleCount,
        };
        
        //console.log(`processing sample ${sampleCount++}`);
        
        // I believe this decode part is asynchronous so to decide if we should display a particular frame or not (if seeking, for example)
        // needs to be done at the decode.output callback level
        decoder.decode(new EncodedVideoChunk({
          type: sample.is_sync ? "key" : "delta",
          timestamp: 1e6 * sample.cts / sample.timescale,
          duration: 1e6 * sample.duration / sample.timescale,
          data: sample.data,
        }));
        
        sampleCount++;
      }
    };
    
    return mp4Box;
  }

  // https://gpac.github.io/mp4box.js/test/ui-helper.js
  function parseFile(fileobj){
    fileSize = fileobj.size;
    startDate = new Date();
    offset = 0;
    frameCount = 0;
    sampleCount = 0;
    samplesProcessed = 0;
    
    clearFrameCanvases();
    images = [];
    frameInfo = {};
    
    mp4Box = createMp4Box();
    
    readBlock(offset, chunkSize, fileobj);
  }

  function start(fileobj){
    // TODO: if a user loads a large mp4 and its samples are still being decoded
    // while the user triggers a seek, that could add unwanted frames to the timeline
    // need to fix (can we cancel the video decoder whenever start() is called or can
    // we know when things are still being processed and prevent any action until finished?)
    currFile = fileobj;
    parseFile(fileobj);
    
    // https://stackoverflow.com/questions/5235145/changing-source-on-html5-video-tag
    const video = document.getElementById('video');
    video.style.display = 'block';
    
    const source = document.createElement('source');
    source.setAttribute('src', URL.createObjectURL(fileobj));
    source.setAttribute('type', 'video/mp4');
    
    // clear any children of video element
    while(video.lastChild){
      video.removeChild(video.lastChild);
    }
    
    video.appendChild(source);
    video.load();
  }

  // TODO: viewing an exported mp4 doesn't look too good on Windows but in Discord for example it seems to render fine? why is that?
  //
  // TODO: is there a way we can allow for frame edits but then get the edited frame to have the original dimensions on save?
  // do we need to read back the samples and then re-edit those? (e.g. maybe something like keep track of edits the user has made 
  // on the canvas'd frames and then on save, reload the samples but use some offscreen canvas to apply the same edits but 
  // keep original dimensions and then write that offscreen canvas to the mp4 file to be saved?)
  //
  async function saveChanges(){
    //console.log(frameInfo);
    const canvasFrames = document.querySelectorAll('canvas');
    if(canvasFrames.length > 0 && currMp4Info.videoTracks.length === 1){
      // NOTE: we're only asuming one video track here.
      const track = currMp4Info.videoTracks[0];
      const codec = track.codec; // NOTE: for some reason, the codec in the exported mp4 doesn't match the one used here :/
      const frameWidth = canvasFrames[0].width;
      const frameHeight = canvasFrames[0].height;
      const totalFrames = canvasFrames.length;
      
      let fps = Math.round(track.nb_samples / (track.duration / track.timescale)); // estimated FPS
      if(fps === Infinity){
        // because track.duration might be 0, try using currMp4Info.duration if so
        fps = Math.round(track.nb_samples / (currMp4Info.duration / currMp4Info.timescale));
      }
      
      // NOTE: we are assuming right now that the number of frames hasn't changed
      // and so the duration should be the same as the original mp4
      // TODO: we should not assume that
      const durationPerFrame = track.nb_samples / track.duration;
      console.log(`saving - durationPerFrame: ${durationPerFrame}`);
      console.log(`saving - num samples: ${track.nb_samples}, track duration: ${track.duration}`);
      console.log(`saving - codec: ${codec}`);
      console.log(`saving - fps: ${fps}`);
      
      const trackOptions = {
        timescale: track.timescale,
        width: frameWidth,
        height: frameHeight,
        nb_samples: totalFrames,
        codec: codec,
        duration: Math.round(totalFrames * durationPerFrame),
      };
      
      const file = MP4Box.createFile();
      
      // copy over some info from the loaded mp4 we're editing
      // TODO: does this part really matter?
      // https://github.com/gpac/mp4box.js/blob/master/src/isofile-advanced-creation.js#L4
      file.init({
        brands: currMp4Info.brands,
        timescale: currMp4Info.timescale,
        duration: currMp4Info.duration,
      });
      
      let trackId = null;
      let chunkCount = 0;
      const videoEncoder = new VideoEncoder({
        output: (chunk, config) => {
          const buffer = new ArrayBuffer(chunk.byteLength);
          chunk.copyTo(buffer);
          
          if(trackId == null){
            trackOptions.avcDecoderConfigRecord = config.decoderConfig.description;
            trackId = file.addTrack(trackOptions);
          }
          
          //console.log(`chunk timestamp: ${chunk.timestamp}`);        
          const sampleData = frameInfo[chunkCount];
          //console.log(sampleData);
          
          const sampleOptions = {
            duration: sampleData.duration,
            dts: sampleData.dts,
            cts: sampleData.cts,
            is_sync: chunk.type === 'key',
          };
          
          chunkCount++;
          
          // add new frame as sample to the mp4 file
          file.addSample(trackId, buffer, sampleOptions);
        },
        error: err => console.error('VideoEncoder error: ', err)
      });
      
      await videoEncoder.configure({
        codec: codec,
        width: frameWidth,
        height: frameHeight,
        bitrate: track.bitrate,
        framerate: fps,
      });
      
      // add the frames to the video encoder
      for(let index = 0; index < totalFrames; index++){
        const bitmap = await createImageBitmap(canvasFrames[index]);
        const videoFrame = new VideoFrame(bitmap, {
          timestamp: frameInfo[index].timestamp,
        });
        
        videoEncoder.encode(videoFrame);
        
        videoFrame.close();
        bitmap.close();
      };
      
      await videoEncoder.flush();
      videoEncoder.close();
      
      // TODO: add audio if present as well
      
      const filenameToSave = document.getElementById('filenameToSave');
      const filename = filenameToSave.value ? `${filenameToSave.value}.mp4` : 'editedVideo.mp4';
      file.save(filename);
    }
  }

  document.getElementById('saveChanges').addEventListener('click', () => saveChanges());
  
  function createCanvasContextMenu(canvasTargetElement){
    const menu = document.createElement('div');
    menu.style.position = 'absolute';
    menu.style.top = (canvasTargetElement.getBoundingClientRect().top + window.scrollY) + 'px';
    menu.style.left = (canvasTargetElement.getBoundingClientRect().left + window.scrollX) + 'px';
    menu.style.border = '1px solid #000';
    menu.style.backgroundColor = 'rgba(255, 255, 255, 125)';
    menu.style.width = canvasTargetElement.style.width + 'px';
    menu.style.height = canvasTargetElement.style.height + 'px';
    menu.style.display = 'block';
    
    const select = document.createElement('select');
    
    const options = [
      '',
      'invert filter',
      'edge detection filter',
      'draw',
      'delete'
    ];
    
    options.forEach(opt => {
      const o = document.createElement('option');
      o.textContent = opt;
      select.appendChild(o);
    });
    
    select.addEventListener('change', evt => {
      const canvasCtx = canvasTargetElement.getContext('2d');
      const imgData = canvasCtx.getImageData(0, 0, canvasTargetElement.width, canvasTargetElement.height);
      
      const selected = evt.target.value;
      
      if(selected === 'invert filter'){
        imageFilterUtils.invertImage(imgData);
        canvasCtx.putImageData(imgData, 0, 0);        
      }else if(selected === 'edge detection filter'){
        imageFilterUtils.edgeDetection(imgData);
        canvasCtx.putImageData(imgData, 0, 0);
      }else if(selected === 'draw'){
        canvasUtils.prepCanvas(canvasTargetElement);
      }else if(selected === 'delete'){
        const ok = confirm('are you sure you want to delete this frame?');
        if(ok){
          canvasTargetElement.parentNode.removeChild(canvasTargetElement);
          if(canvasContextMenu){
            canvasContextMenu.parentNode.removeChild(canvasContextMenu);
            canvasContextMenu = null;
          }
        }
      }
    });
    
    menu.appendChild(select);
    
    document.body.appendChild(menu);
    
    canvasContextMenu = menu;
  }

  document.body.addEventListener('pointerdown', evt => {
    if(evt.target.tagName !== 'CANVAS' && evt.target.tagName !== 'SELECT' && canvasContextMenu){
      canvasContextMenu.parentNode.removeChild(canvasContextMenu);
      canvasContextMenu = null;
    }
  });
  
  document.getElementById('reloadFile').addEventListener('click', evt => {
    if(currFile && !isProcessing){
      start(currFile);
    }else if(isProcessing){
      document.getElementById('stillProcessing').style.display = 'block';
    }
  });
  
  document.getElementById('seek').addEventListener('click', evt => {
    if(isSeeking){
      console.log('seek is currently in progress');
      document.getElementById('stillProcessing').style.display = 'block';
      return;
    }
    
    if(isProcessing){
      console.log('file is still processing');
      document.getElementById('stillProcessing').style.display = 'block';
      return;
    }
    
    if(currFile){
      seekStart = parseInt(document.getElementById('seekStart').value) || 0;
      seekEnd = parseInt(document.getElementById('seekEnd').value) || 0;
      
      const seekLimit = 5; // currently add a hard limit on seek range so as to not create too many canvases for frames (not sure how many canvases a page can handle but just for now at least)
      
      // get length of mp4 in seconds
      const lengthOfMp4 = Math.round(currMp4Info.videoTracks[0].duration / currMp4Info.videoTracks[0].timescale);
      //console.log(lengthOfMp4);
      
      if(seekStart < 0 || seekEnd < 0){
        console.error('seekStart or seekEnd is less than 0, which is invalid.');
        document.getElementById('seekValuesInvalidModal').style.display = 'block';
        return;
      }else if(seekStart >= lengthOfMp4){
        console.error('seekStart is larger than or equal to the duration of the mp4 file. seekStart should be at least 0 but less than the duration of the file.');
        document.getElementById('seekStartTooLargeModal').style.display = 'block';
        return;
      }else if(seekEnd > lengthOfMp4){
        console.error('seekEnd is larger than the duration of the mp4 file.');
        document.getElementById('seekEndTooLargeModal').style.display = 'block';
        return;
      }else if(seekEnd <= seekStart){
        console.error('seekEnd is less than or equal to seekStart. seekEnd should be larger than seekStart.');
        document.getElementById('seekEndTooSmallModal').style.display = 'block';
        return;
      }else if(seekEnd - seekStart > seekLimit){
        console.error(`seek range must not exceed ${seekLimit} seconds. sorry!`);
        document.getElementById('seekLimitModal').style.display = 'block';
        return;
      }
      
      isSeeking = true;
      //console.log(`seekStart:${seekStart}, seekEnd:${seekEnd}`);
      
      start(currFile);
    }
  });
  
  document.getElementById('notes').addEventListener('click', async (evt) => {
    /*
    const notes = [
      "Notes:",
      "This has not been tested yet on mp4 files longer than 10 minutes so success with such files may vary (that said, there may be small mp4 files that may break this app as well :D ).",
      "Only up to 100 frames will be displayed at a time. Seeking is currently limited to a range of 5 seconds.",
      "Additionally, when saving edits, the image quality unfortunately is not preserved (so it may look worse than the source file) and any audio tracks are not included in the output.",
    ];
    await modal.createMessageModal(notes);
    */
    document.getElementById('notesModal').style.display = 'block';
  });

  </script>
</body>

</html>